---
layout: post
title: CUDA| QQQ量化中GEMM算子的研究
categories: [CUDA]
description: QQQ量化中GEMM算子的研究
keywords: CUDA; GEMM
mermaid: false
sequence: false
flow: false
mathjax: true
mindmap: true
mindmap2: false
---

## QQQ量化中GEMM算子的研究

在自然语言处理领域，大型语言模型（LLM）在自然语言处理领域的应用越来越广泛。然而，随着模型规模的增大，计算和存储资源的需求也急剧增加。为了降低计算和存储开销，同时保持模型的性能，LLM大模型的量化技术应运而生。LLM大模型的量化技术主要是通过对模型参数进行压缩和量化，从而降低模型的存储和计算复杂度。具体来说如下：

- 参数压缩：通过将模型中的浮点数参数转换为低精度的整数参数，量化技术可以实现参数的压缩。这不仅可以减少模型所需的存储空间，还可以降低模型加载的时间。
- 计算加速：由于低精度整数运算的速度远快于浮点数运算，量化技术还可以通过降低计算复杂度来实现计算加速。这可以在保证模型性能的同时，提高模型的推理速度。
- 量化技术的三个主要目的：节省显存、加速计算、降低通讯量。

##### QQQ量化的流程与效果

![](/images/cuda/1.png)

![](/images/cuda/2.png)

![](/images/cuda/3.png)

